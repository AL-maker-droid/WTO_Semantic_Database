NBER WORKING PAPER SERIES
TAPPING THE SUPERCOMPUTER UNDER YOUR DESK:
SOLVING DYNAMIC EQUILIBRIUM MODELS WITH GRAPHICS PROCESSORS
Eric M. Aldrich
Jesús Fernández-Villaverde
A. Ronald Gallant
Juan F. Rubio-Ramírez
Working Paper 15909
http://www.nber.org/papers/w15909
NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
April 2010
We thank Panayiotis Stavrinides, who first pointed out to us the potential of GPUs, Kennetz Czechowski
for invaluable technical help, and the NSF for research support under several grants. The views expressed
herein are those of the authors and do not necessarily reflect the views of the National Bureau of Economic
Research.
NBER working papers are circulated for discussion and comment purposes. They have not been peer-
reviewed or been subject to the review by the NBER Board of Directors that accompanies official
NBER publications.
© 2010 by Eric M. Aldrich, Jesús Fernández-Villaverde, A. Ronald Gallant, and Juan F. Rubio-Ramírez.
All rights reserved. Short sections of text, not to exceed two paragraphs, may be quoted without explicit
permission provided that full credit, including © notice, is given to the source.

Tapping the Supercomputer Under Your Desk: Solving Dynamic Equilibrium Models with
Graphics Processors
Eric M. Aldrich, Jesús Fernández-Villaverde, A. Ronald Gallant, and Juan F. Rubio-Ramírez
NBER Working Paper No. 15909
April 2010
JEL No. C87,E0
ABSTRACT
This paper shows how to build algorithms that use graphics processing units (GPUs) installed in most
modern computers to solve dynamic equilibrium models in economics. In particular, we rely on the
compute unified device architecture (CUDA) of NVIDIA GPUs. We illustrate the power of the approach
by solving a simple real business cycle model with value function iteration. We document improvements
in speed of around 200 times and suggest that even further gains are likely.
Eric M. Aldrich
213 Social Sciences Building,
Duke University
Durham, NC 27708
ealdrich@gmail.com
Jesús Fernández-Villaverde
University of Pennsylvania
160 McNeil Building
3718 Locust Walk
Philadelphia, PA 19104
and NBER
jesusfv@econ.upenn.eduA. Ronald Gallant
Fuqua School of Business
Duke University
1 Towerview Drive
Durham, NC 27708
aronaldg@gmail.com
Juan F. Rubio-Ramírez
Duke University
P.O. Box 90097
Durham, NC 27708
juan.rubio-ramirez@duke.edu

1.Introduction
Thispapershowshowtobuildalgorithmsthatusegraphicspr ocessingunits(GPUs)tosolve
dynamic equilibrium models in economics. In particular, we rely on the compute unied
devicearchitecture(CUDA)ofNVIDIA.Wereporthowthisapp roachleadstoremarkable
improvements in computation time. As an example, we solve a b asic real business cycle
(RBC) model with value function iteration. We document how u sing the GPU delivers a
speedimprovementofaround200times.
GPUs, avital piece of moderncomputingsystems,1arespecializedprocessorsdesigned
torendergraphics(linearalgebra-likecomputations)for electronicgamesandvideoapplica-
tions. Theincreasingdemandforthesedevices,fueledbyth evideogameindustrysinsatiable
appetite for improved graphics processing performance, ha s forged a market for low-cost
processingunitswiththenumber-crunchinghorsepowercom parabletothatofasmallsuper-
computer. Toillustratethispoint,wereportintable1thet heoreticalpeakperformanceof
twomodernGPUsversustwotraditionalcentralprocessingu nits(CPUs),expressedasbil-
lionsofarithmeticoperationsthatcanbecomputedeachsec ond(GFLOP/s),bothinsingle
anddoubleprecision.
Table1: TheoreticalpeakperformanceofGPUsversusCPUs
SingleGFlopg/s DoubleGFlopg/s
GeForcemx280[GPU] 933 78
RadeonHD5870[GPU] 2720 544
IntelXeonE5345(Clovertown)[CPU] 37.4 37.4
AMDOpteron2356(Barcelona)[CPU] 38.6 38.6
As specialized compute-intensive hardware, GPUs can devot e more transistors to data
processingthangeneralpurposeCPUs. ThisgivesrisetoGPU architectureswithhundreds
ofcores(asopposedtothedualorquadcoreCPUscommontoday )withasharedmemory
and,therefore,well-suitedtoaddressproblemsthatcanbe expressedasdata-parallelcompu-
tations.2However,sinceGPUswereinitiallydesignedforrendering3 Dgraphicsandtheset
ofinstructionswerespecictoeachparticularGPU,forman yyearsitwasdi¢culttoexploit
themasgeneralpurposecomputingdevices.
1MostcomputershaveaGPUpre-installedinthefactory,eitherinthemotherboardorinavideocard.
2Traditionalalternativessuchasmessagepassinginterface(MPI)forparallelcomputingonmanyCPUs
rely heavily on distributed memory. This requires the programmer to ensure that all di¤erent parts of the
coderunninginparallelhaveaccesstothecorrectamountofinformationattherighttimetoavoidlatency
periods that diminish performance. Shared memory gets around this problem because, if the values of the
relevantvariablesareinthesharedregion,theyarevisibletoalltherelevantthreads.
2

In2007,NVIDIA,oneoftheleadingproducersofGPUs,disrup tedthesupercomputing
communitybyreleasingCUDA,asetofdevelopmenttoolsthat allowprogrammerstoutilize
the tremendous computing capabilities of the GPU for genera l purpose computations. To
date,CUDAcontinuestobethetrend-setterandmostpopular implementationofthispro-
grammingapproach,knownasgraphicsprocessingunitscomp uting(GPUcomputing). This
innovationgivesprogrammersaccesstoanapplicationprog ramminginterface(API)thatal-
lowsthemtoeasilyissueandmanagecomputationsontheGPUa sadata-parallelcomputing
devicewithouttheneedtounderstandthedetailsofthehard wareorwriteexplicitlythreaded
code.
Furthermore,theCUDAdevelopmenttoolscanbedownloadedf orfreefromtheinternet
andinstalledinafewminutesonanyregularcomputerwithan NVIDIAGPU.SinceCUDA
programminguses C for CUDA,adialectofC/C++,oneofthemostpopularprogramming
languages,fastcodedevelopmentisnaturalforexperience dprogrammers. Moreover,thepro-
gramming community has made available third-party wrapper s inFortran,Java,Python,
andMatlab(amongothers),whichcoverallthemajorlanguagesusedbyt hescienticcom-
putingworld.
The emergence of GPUcomputing has the potential to signica ntly improve numerical
capabilitiesineconomics. Althoughnotallapplicationsa reparallelizeableorhavethearith-
meticdemandstobenetfromGPUcomputing,manycommoncomp utationsineconomics
twithintheconstraintsoftheapproach. Forexample,eval uatingthelikelihoodfunctionof
amodelforalternativeparameters,checkingthepayo¤sofa vailablestrategiesinagame,and
performingvaluefunctioniterationareprimecandidatesf orcomputationonaGPU.Overthe
lastseveraldecades,alloftheseproblemshavecommandedt heattentionofresearchersacross
di¤erentareasineconomics. Butevenwiththemostupdatedc omputers,manyversionsof
theseproblems,fromthesolutionofmodelswithheterogene ousagentstotheestimationof
rich structural models or the characterization of equilibr ium sets of repeated games, have
remainedtooburdensomeforcomputationinareasonableamo untoftime. GPUcomputing
hasthepotentialtoeasemanyofthesecomputationalbarrie rs.
GPUcomputinghasalreadybeensuccessfullyappliedinbiol ogy,engineering,andweather
studies, among other elds, with remarkable results. Howev er, GPU computing has expe-
rienced a slow uptake in economics.3To address this void, this paper demonstrates the
potential of GPUs by solving a basic RBC model. We selected th is application because a
commonapproachtosolvingthismodelistousevaluefunctio niteration,analgorithmthatis
particularlyeasytoexpressasadata-parallelcomputatio n. Sinceinnumerablemodelsfrom
3Weareonlyawareofapplicationsintherelatedeldofstatistics,asinLee etal.(2008).
3

variouspartsofeconomicscanbecastintheformofadynamic programmingproblem,our
applicationisrepresentativeofalargerclassofsituatio nsofinterest.
Ourmainndingisthat, usingvaluefunctioniterationwith abinarysearch, theGPU
solves the RBCmodel roughly 500 times fasterthanthe CPUfor a gridof 262,144 points
(65,536pointsforcapitaland4pointsforproductivity). T hisprovestheimmensepromise
of graphics processors for computation in economics. Paral lelization, nevertheless, is less
powerfulinsomealgorithms. Toillustratetheselimitatio ns,werecomputeourmodelwitha
Howardimprovementmethodandgridsearch. Inthiscase,the GPUisonly3timesfaster
than the CPU, a noticeable improvement, but not as spectacul ar as before. When we let
eachprocessorusethemethodforwhichitisbestsuited,adi ¤erenceof200timesfavorsthe
GPU.
Aswewillemphasizeinsection4,thesenumbersarealowerbo undforthepossiblespeed-
upsdeliveredbygraphicsprocessors. First,weareusingaG PUwith240processorsbutthere
arealreadyGPUcardswith1920processorsandlargermemory availableonthemarket(with
substantiallymorepowerfulGPUstobereleasedinthenextf ewmonths). Second,algorithm
designisboundtoimprovewithexperience.
The rest of the paper is organized as follows. Section 2 descr ibes the basic ideas of
parallelizationinGPUs. Section3presentsourRBCmodelan dthecalibration. Section4
reportsournumericalresults. Section5concludeswithsom enalremarksanddirectionsfor
futureresearch.
2.ParallelizationinGPUs
Itiswellknownthat,conceptually,itistrivialtoparalle lizeavaluefunctioniteration. The
extensiontoGPUsisalsostraightforward. Asimpleparalle lizationschemeforGPUswould
beasfollows:
1. Determinethenumberofprocessorsavailable, P,intheGPU.
2. Selectanumberofgridpoints, N,andallocatethemoverthestatespace. Forexample,
if the state variables are capital and productivity, pick Nkdiscrete points for capital
andNzpointsforproductivitywith N=NkNz.
3. Dividethe Ngridpointsamongthe PprocessorsoftheGPU.
4. Make an initial guess V0. Under standard assumptions any guess will converge, but
additionalinformationsuchasconcavitymaygenerateagoo dguessthatwillleadtoa
fastersolution.
4

5. CopyV0tothesharedmemoryoftheGPU.
6. Eachprocessorcomputes V1,givenV0,foritsdesignatedsubsetofgridpoints. Since
thememoryisshared,attheendofthisstep,allprocessors seeV1.
7. Repeatstep6untilconvergence: kVi+1 Vik<".
8. CopyVifromtheGPUmemorytothemainmemory.
Whilethepreviousalgorithmistransparent,itspractical codingrequiressomecare. For
example,ashasbeenrepeatedlypointedoutintheparallelp rogrammingliterature,wewant
toavoidbranchinstructionssuchasifstatements,becau setheymaythrowtheprocessors
out of synchronization and force the code to be executed seri ally. In addition, to obtain
a superior performance, one needs to spend a bit of time learn ing the details of memory
management of the GPU. Since those are specic to each archit ecture, we avoid further
discussion. Su¢ce it tosaythat, as the GPUcomputing techno logymatures, these details
willbecomeirrelevantfortheaverageuser(astheyarenowa daysforCPUs).
Theinterestedreadercanndthecodeandfurtherimplement ationdetailsatthecom-
panionwebpage: http://www.ealdrich.com/Research/GPUVFI/ .
3.AnApplication: AnRBCModel
For reasons of simplicity and generality that we outlined in the introduction, we pick as
our illustrative application of the potentialities of grap hics processors a basic RBC model,
inwhicharepresentativehouseholdchoosesasequenceofco nsumptionctandcapitalktto
maximizetheutilityfunction
E01X
t=0tc1 
t
1 ;
whereE0istheconditionalexpectationoperation, thediscountfactor,and riskaversion,
subjecttoabudgetconstraint
ct+it=wt+rtkt;
wherewtisthewagepaidfortheunitoflaborthatthehousehold(inel astically)suppliesto
themarket,rtistherentalrateofcapital,and itisinvestment. Capitalisaccumulatedgiven
alawofmotion
kt+1=(1 )kt+it;
whereisthedepreciationfactor.
5

Finally, there is a representative rm with technology yt=ztk
t, where productivity zt
evolvesasanAR(1)inlogs:
logzt=logzt 1+"t;where"tN(0;2):
Therefore,theresourceconstraintoftheeconomyisgivenb y
kt+1+ct=ztk
t+(1 )kt:
Giventhatthewelfaretheoremsholdinthiseconomy,weconc entrateonsolvingthesocial
plannersproblem. Thisproblemcanbeequivalentlystated intermsofavaluefunction V(;)
andaBellmanoperator
V(k;z)=max
cc1 
1 +E[V(k0;z0)jz] (1)
s.t.k0=zk+(1 )k c
thatcanbefoundwithvaluefunctioniteration. While,inth einterestofspace,wedirectly
jumpintotheproblemofasocialplanner,thisisnotrequire d. Theimportantpointisthat
wearehandlingatasksuchasvaluefunctioniterationthati sinherentlystraightforwardto
paralellize. Dozensofothermodels,frommacroeconomicst oindustrialorganizationorgame
theory,generatesimilarformulationsintermsofBellmano perators. Therefore,thelessons
fromourapplicationcarryforwardtoallofthesesituation snearlyunchanged.
Beforeproceedingfurther,weneedtoselectvaluesforthes ixparametersofourmodel.
Wepickstandardnumbersforaquarterlycalibration. Thedi scountfactor, =0:984,yields
areturnoncapitalofaround6.6percentandthecapitalinco meshare,=0:35,matchesthe
observationsinthedata. Depreciation, =0:01;andriskaversion, =2,areconventional
choices. TheparametersoftheARprocessforproductivity, =0:95;and=0:005,match
thepropertiesoftheSolowresidualoftheU.S.economy. Tab le2summarizesthecalibration
ofthemodel.
Table2: Calibration

0:98420:350:010:950:005
6

4.Results
Wecodedthevaluefunctioniterationthatsolvesequation( 1)inC++(withtheGNUcompiler)
toimplementthetraditionalapproachonaCPU.Wethencoded thesameproblemin C for
CUDAtosolveitonaGPUwithdoubleprecision. Thetestmachinewa saDELLPrecision
WorkstationR5400withtwo2.66GHzquadcoreIntelXeonCPUs andoneNVIDIAGeForce
GTX280GPU.TheGeForceGTX280has30multiprocessors,each composedof8processors,
foratotalof240cores.
Wediscretizedtheproductivityprocesswithfourquadratu repointsfollowingTauchens
(1986) procedure. With respect to capital, we discretized i ts values for a sequence of in-
creasinglynegrids. ThishelpedusgaugehowCUDAworkswit hdi¤erentgridsizesandto
extrapolateforasymptoticallylargegrids. Westoppedat6 5,536becausebythattimethe
Eulerequationerrorsoftheapproximationaresu¢cientlys mall. Allthecapitalgridswere
uniformandwepickedfuturecapitalpointsfromwithintheg rid(wealsocomputedthecase
wherewerelaxthischoicebyallowinginterpolationoutsid ethegrid,moredetailsbelow). In
allofourexercises,westartedwiththeutilityoftherepre sentativehouseholdinthedeter-
ministicsteadystateasour V0andtheconvergencecriterionwas kVi+1 Vik<(1 )1 8;
wherekkisthesupnorm.
Formaximization,weimplementedtwoprocedures. First,as abenchmark,weemployeda
binarysearch(amethodthatrequiresconcavityontheobjec tivefunction). TheCPUversion
exploited the monotonicity of the value function to place co nstraints on the grid of future
capitaloverwhichthemaximizationisperformed. Thisisno tpossibleundertheGPUversion,
as it creates dependencies that are not parallelizable. Our secondmaximizationprocedure
wasagridsearchwithaHowardimprovementstep: wemaximize dthevaluefunctiononly
everyn thiterationofthealgorithm,where nisdecidedbytheuser(wedidnotrelyon
aHowardstepforbinarysearchsinceitdoesnotpreservecon cavityinthestepswhereno
maximizationisperformed). Inourcase,aftersomene-tun ingtooptimizetheperformance
ofthealgorithm,weselected n=20:
Ourmainresults appearin table 3, where we report GPUandCPU solutiontimes (in
seconds)foranincreasingsequenceofcapitalgridsizes(r owNk). Westartwith16points
forcapitalandmultiplythenumberbytwountilwehave65,53 6points. TheGPUmethod
generatesatimingoverheadcostofapproximately1.13seco ndsformemoryallocation. This
isthexedcostofstartingCUDAmemoryallocationand,henc e,roughlyindependentofthe
sizeandquantityofobjectstobeallocated. Forthisreason ,theGPUtimesareseparated
intomemoryallocation(secondrow)andsolution(thirdrow )components. Thelasttworows
reporttheratiosofGPUsolutiontimetoCPUsolutiontimean dtotalGPUtimetoCPU
7

solutiontime,respectively.
Forcoarsegrids,thexedcostofparallelprogrammingover comestheadvantagesofthe
GPU,butbythetimethereare128gridpointsofcapital,theG PUstartstodominate. With
65,536capitalgridpointsandcountingthememoryallocati on,theGPUisroughly509times
faster, and, withoutcountingit, 521times. Thekeyforthis resultisthat, whiletheGPU
computationtimegrowslinearlyinthenumberofgridpoints thankstoitsmassivelyparallel
structure,theincreaseisexponentialfortheCPU,yetanot hermanifestationofthecurseof
dimensionality.
Table3: TimetosolveanRBCmodelusingvaluefunctionitera tion,case1
ObservedTimes(seconds)
Nk 16 32 64 128 256 512 1,024
GPUMemoryAllocation 1.13 1.13 1.13 1.12 1.13 1.12 1.12
GPUSolution 0.29 0.32 0.36 0.4 0.44 0.57 0.81
GPUTotal 1.42 1.45 1.49 1.52 1.57 1.69 1.93
CPU 0.03 0.08 0.19 0.5 1.36 3.68 10.77
Ratio(solution) 9.667 4.00 1.895 0.80 0.324 0.115 0.075
Ratio(total) 47.333 18.125 7.842 3.04 1.154 0.459 0.179
ObservedTimes(seconds)
Nk 2,048 4,096 8,192 16,384 32,768 65,536
GPUMemoryAllocation 1.12 1.12 1.13 1.12 1.13 1.13
GPUSolution 1.33 2.53 5.24 10.74 22.43 47.19
GPUTotal 2.45 3.65 6.37 11.86 23.56 48.32
CPU 34.27 117.32 427.50 1,615.40 6,270.37 24,588.50
Ratio(solution) 0.039 0.022 0.012 0.007 0.004 0.002
Ratio(total) 0.071 0.031 0.015 0.007 0.004 0.002
Intable4,weextrapolatecomputationtimesformoredenseg rids. Thispractice,common
inscienticcomputing,indicateshowthemethodswouldwor kasymptoticallyasweincrease
the number of grid points. By adjusting a simple linear regre ssion of the square root of
computationtimeon Nk,weguessthat,forlargegrids,theratiostabilizesaround 0.002,or
that our RBC model would take around 500 times as long to solve on the CPU as on the
GPU.Theadjusted R2valuesoftheregressionsare0.999(GPU)and0.999(CPU).
8

Table4: TimetosolveanRBCmodelusingvaluefunctionitera tion,case1
ExtrapolatedTimes(seconds)
Nk 131,072 262,144 524,288 1,048,576 2,097,152 4,194,304
GPUSolution 195.767 734.498 2,843.185 11,185.46 44,369.609 176,736.311
CPU 98,362.384 392,621.758 1,568,832.79 6,272,023.978 25,081,482.86 100,312,706.6
Ratio 0.002 0.002 0.002 0.002 0.002 0.002
Itisimportant,however,torememberthatsomealgorithmsy ieldalowerreturntoparal-
lelization. Table5reportstheresultsofoursameexercise ,butnowweemployagridsearch
withHowardstep. Thisstepnotablyreducesthelengthofcom putationtimeontheCPU,
butnotontheGPU(whichactuallybecomesworseforlargegri ds). Consequently,nowthe
improvementsareonly3times. Asbefore,werunaregression ofthesquareofcomputation
timeonNktogaugetheasymptoticbehaviorofeachprocessor. Weomitt hoseresultsinthe
interestofspace,butsu¢ceittosaythattheratiostabiliz esaround0.343.
Table5: TimetosolveanRBCmodelusingvaluefunctionitera tion,case2
ObservedTimes(seconds)
Nk 16 32 64 128 256 512 1,024
GPUMemoryAllocation 1.13 1.13 1.13 1.13 1.13 1.13 1.12
GPUSolution 0.14 0.16 0.20 0.25 0.24 0.53 1.50
GPUTotal 1.27 1.29 1.33 1.38 1.37 1.66 2.62
CPU 0.02 0.03 0.07 0.17 0.40 1.11 3.52
Ratio(solution) 7.00 5.33 2.857 1.471 0.600 0.477 0.426
Ratio(total) 63.50 43.00 19.00 8.118 3.425 1.495 0.744
ObservedTimes(seconds)
Nk 2,048 4,096 8,192 16,384 32,768 65,536
GPUMemoryAllocation 1.13 1.13 1.11 1.13 1.12 1.13
GPUSolution 4.29 15.12 57.83 222.46 875.26 3,469.78
GPUTotal 5.42 16.25 58.94 223.59 876.38 3,470.91
CPU 12.52 42.85 166.43 639.89 2,527.32 10,056.00
Ratio(solution) 0.343 0.353 0.347 0.348 0.346 0.345
Ratio(total) 0.433 0.379 0.354 0.349 0.347 0.345
Finally,intable6wecomparetheratiooftimesfortheGPUso lutionwithbinarysearch
andtheCPUsolutionwithgridsearchandHowardimprovement . Thisgivesusanideaof
the speed di¤erences when each processing unit is working wi th the method to which it is
comparativelybestsuited(sincetheconvergencecriterio nisverytight,theresultsinterms
9

ofvalueandpolicyfunctionsarenearlyidentical). Therat iogivestheGPUanadvantageof
208timesfor65,536capitalgridpoints.
Table6: RatiosofComputingTime
ObservedTimes(seconds)
Nk16 32 64 128 256 512 1,024
Ratio14.50 10.667 5.143 2.353 1.100 0.514 0.230
ObservedTimes(seconds)
Nk2,048 4,096 8,192 16,384 32,768 65,536
Ratio0.106 0.059 0.031 0.017 0.009 0.005
Aswementionedbefore,theresultsreportedintables3-6co rrespondtoasolutionmethod
thatconstrainsthevaluesoffuturecapitaltothesamegrid aspresentcapital;thatis,itdoes
notallowforinterpolation. Assuch,thegrid-basedmaximi zationproceduremustevaluate
thevaluefunction Nktimesinordertodetermineamaximum. When Nkisverylarge,the
grid-basedmaximizationcanbequiteslow,especiallyfort heGPU(relativetotheCPU).An
alternative solution method that we implement (results are not reported for consideration
of space) xes the grid of future capital values, independen t of the grid of current capital,
andevaluatesthevaluefunctionusingpiecewiselinearint erpolation. Inourimplementation,
we chose the grid of future capital to have both 100 and 1,000 p oints, and found that the
GPUwasnowroughly30timesfaster(inbothcases)thantheCP UwhenNk=65,536and
roughly 40 times faster (in both cases) asymptotically. We c an compare this result to the
non-interpolation method (table 5), where the GPU is only ab out 3 times faster than the
CPU.
ThereasonfortherelativelypoorperformanceoftheGPUusi ngthenon-interpolation
solutionmethodisthattheGPUlosesitspowerasthenumbero fserialoperationsoneach
processingunitincreases. Thatis, forthenon-interpolat ionmethod, eachofthe240GPU
processorsisperformingroughly65,536serialoperations forthelargestgridateachstepof
theVFI.Comparethistotheinterpolationsolutions,where thenumberofserialoperations
isonly100and1,000. Intuitively,asweincreasethenumber ofserialoperationsoneachof
theGPUprocessors,weareusingthemmoreandmoreliketradi tionalCPUs-somethingfor
whichtheyarenotoptimized. Hence,onewaytoimprovethepe rformanceoftheGPUwhen
using a grid search for large grids is to allowfor interpolat ion. The results may not be as
strikingforsmallergrids,wherethecostofinterpolation mayoutweighthebenetgainedby
evaluatingthevaluefunctionatfewerpoints. Forthecases thatweimplemented(100and
1,000pointgridsforfuturecapital),interpolationwason lybenecialfortheGPUwhenthe
10

gridsforcurrentcapitalhad512and4,096points,respecti vely. Thesamewastrueforthe
CPUwhenthegridsforcurrentcapitalhad2,048and32,768po ints,respectively. Wenote
thatthebinarysearchmethodisnotlikelytoenjoythesameb enetsofinterpolation,since
thenumberofvaluefunctionevaluationsinthemaximizatio nislowandmoreorlessxed,
independentof Nk.
We would like to emphasize that we interpret our results as a lowerbound on the ca-
pabilitiesofgraphicsprocessors. OurGPU,GeForceGTX280 witharchitectureGT200,is
an o¤-the-shelf consumer product primarily geared to consu mer graphics applications. In
comparison:
1. Nowadays, there are PCs with up to eight NVIDIA Tesla C1060 cards. Each Tesla
cardpacks240processorsandamuchlargermemory(upto4Gba gainstthe1Gbof
theGeForce). OurreadingoftheCUDAdocumentationmakesus forecastthatusing
aeight-cardmachine(with1,920processorsinsteadof240) woulddividecomputation
timebyeight. Ifourestimateturnsouttobecorrect,thebas icRBCmodelwouldtake
around1,600timesaslongtosolve(withvaluefunctioniter ation)ontheCPUason
eightTeslaGPUs.
2. NVIDIA has announced that it will release the next generat ion of CUDA architec-
ture(codename: Fermi)inMarch2010.4TheGraphicsFermi100(GF100)graphics
processordisplays512cores,deliveringupto8timesasman ydoubleprecisionopera-
tionsperclockcyclerelativetothecurrentarchitecture, andallowsconcurrentkernel
execution. Theamountofsharedmemorypermultiprocessori s4timesaslarge,which
cangreatlyminimizedatatransferandspeedcomputations( infact, wesuspectdata
transferisabindingconstraintforourcoderightnow). Thi swillproducesubstantial
gains. More important, it demonstrates that researchers ar e demandingfasterGPUs
andthattheindustrywillsatisfythem.
3. OurversionofthealgorithmintheGPUiselementary,ande xpertsinothereldshave
learnedmuchabouthowtoadapttheiralgorithmstoachieveo ptimalperformancefrom
theGPUs. Aseconomistscatchupwiththisexpertise,wefore seefurtherimprovements
inspeed.
4Seehttp://www.nvidia.com/object/fermi_architecture.html
11

5.ConcludingRemarks
Thispaperdoesnotaddanytheoreticalmachinerytoeconomi cs,butratherisintendedto
introducereaderstoacomputationalmethodologythatwill improvethee¢ciencyofresearch.
Computationsthathavetraditionallytakenhourscanbecom pletedinsecondsnow. Thisis
signicantbecauseitallowsresearcherstocalculateresu ltstoahigherlevelofprecisionor
explorestatespacesthatwerepreviouslyintractable.
Therearemanydirectionsforfutureresearch. First,ourin tentistorewriteourcodein
OpenCL (Open Computing Language) ,acloserelativeof C for CUDAthatworksinasimilar
mannerandwhichisalsosupportedbyNVIDIA. OpenCLisaframeworkforcross-platform,
parallelprogramming,whichincludesbothalanguage, C99,amoderndialectof C,plusAPIs
to dene and control platforms.5Although, unfortunately, the current version of OpenCL
isnotobjectoriented,thisexerciseisinterestingbecaus ethenewprogramminglanguageis
quicklyexpandingwithintheindustry. Asecondavenueforr esearchistotesthowGPUswork
forothertypesofalgorithmscommonlyusedineconomics,su chasprojectionorperturbation
methods. Wehopeadditionalndingsregardingthesequesti onswillbeforthcomingsoon.
References
[1] Lee, A., C. Yau, M.B. Giles, A. Doucet, and C.C. Holmes (20 08). On the Utility of
Graphic Cards to Perform Massively Parallel Simulation wit h Advanced Monte Carlo
Methods.Mimeo,OxfordUniversity.
[2] Tauchen,G.(1986),FiniteStateMarkov-chainApproxi mationstoUnivariateandVector
Autoregressions. EconomicsLetters 20,177-181.
5Seehttp://www.khronos.org/opencl/ .
12